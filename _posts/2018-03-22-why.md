---
title: 为什么开设 Apache MXNet 博客
header: 为什么开设 Apache MXNet 博客
author: 李沐 Amazon AI Principal Scientist
---



半年前我们开始了一个实验性质的项目：通过代码实现来从0开始学深度学习。因为我们认为深度学习是一门动手的学科，只有通过亲手实现和实验才能体会到各个细节是如何影响最终结果，从而可以应用深度学习来解决实际问题。

我们假设小伙伴有一定的编程基础，但只有极为有限的机器学习和数学知识。然后通过每周直播一到两个小时，现场演示各个模型算法的实现，和在真实数据上不同参数下的结果，以及一系列的Kaggle竞赛练习和论坛讨论。这个项目持续了半年，并取得了一系列结果：

- [70+教程](http://zh.gluon.ai/index.html) 和 [26小时课程视频](https://discuss.gluon.ai/t/topic/753)，覆盖了从线性回归到卷积/循环神经网络，从计算机视觉到自然语言处理
- 数千个小伙伴参与了课程，[数万的论坛讨论](https://discuss.gluon.ai/)，大家刷爆了好几个Kaggle竞赛，例如 [CIFAR-10](https://discuss.gluon.ai/t/topic/1545/) 和 [ImageNet Dog](https://discuss.gluon.ai/t/topic/2399/)


这个项目并没有结束。接下来我们会继续介绍深度学习里的其他方面，例如强化学习和GAN。

但很多小伙伴也提出了其他的需求。特别在是在掌握了基础知识的时候，大家希望如何才能进一步提升来赶上深度学习研究和工业界应用的前沿。例如

- 如何重现最新论文结果。例如 Inception V3 刚发布时因为论文里缺少很多关键性的描述导致重复非常困难。
- 如何在多台 GPU 机器上快速训练，使得我们可以使用规模远大于公开数据集的数据
- 如何将训练好的模型部署在服务器上来服务客户请求

这些知识，或者说经验，比较难以放入入门的课程中。所以我们想通过这个博客，邀请 Apache MXNet 社区的各个小伙伴来分享他们的经验。

我们假设这个博客的读者有了一定的编程和深度学习基础，例如已经完成 [动手学深度学习](https://discuss.gluon.ai/t/topic/753) 这门课程。我们仍然会像以前那样关注动手，关注细节。但会分享更加接近研究和实际应用的一些心得和体会，以及躺过的坑。

敬请期待。

[吐槽和讨论欢迎点这里](https://discuss.gluon.ai/t/topic/5455)
